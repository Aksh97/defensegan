{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import _init_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "../tflib/plot.py:6: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n",
      "    app.start()\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-5f1547943310>\", line 2, in <module>\n",
      "    get_ipython().magic(u'matplotlib inline')\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2336, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2257, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-106>\", line 2, in matplotlib\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/magic.py\", line 193, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/magics/pylab.py\", line 100, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3132, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/IPython/core/pylabtools.py\", line 275, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 229, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/scratch0/pyenv/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pip.utils import ensure_dir\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import cPickle\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from models.gan import MnistGAN, CifarGAN, FmnistGAN, CelebaGAN\n",
    "from utils.config import load_config\n",
    "from utils.gan_defense import model_eval_gan\n",
    "from utils.network_builder import model_a, model_b, model_c, model_d, model_e, model_f, model_z\n",
    "from utils.visualize import save_images_files\n",
    "import keras.backend as K\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import math\n",
    "from cleverhans.utils import batch_indices, _ArgsWrapper, create_logger, set_log_level\n",
    "\n",
    "import os\n",
    "from datasets.celeba import CelebA\n",
    "from datasets.dataset import PickleLazyDataset\n",
    "from defense import get_train_test\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "ds_gan = {'mnist': MnistGAN, 'cifar': CifarGAN, 'f-mnist': FmnistGAN, 'celeba' : CelebaGAN, 'celeba_wider' : CelebaGAN}\n",
    "orig_data_paths = {k: 'data/cache/{}_pkl'.format(k) for k in ds_gan.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = lambda x : x.reshape([x.shape[0],-1])\n",
    "def inv_onehot(ys):\n",
    "    assert len(np.shape(ys)) > 1\n",
    "    return np.argmax(ys,axis=1)\n",
    "\n",
    "def convert_to_onehot(ys):\n",
    "    max_y = int(np.max(ys))\n",
    "    y_one_hat = np.zeros([len(ys), max_y + 1], np.float32)\n",
    "    for (i, y) in enumerate(ys):\n",
    "        y_one_hat[i, int(y)] = 1.0\n",
    "    return y_one_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.mnist import Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_train = Mnist()\n",
    "_ = ds_train.load()\n",
    "ds_val = Mnist()\n",
    "_ = ds_val.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "[#] Max: 1.0, Min: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(ds_train.X.shape)\n",
    "ds_train.X = ds_train.X / 255.0\n",
    "ds_val.X = ds_val.X / 255.0\n",
    "print('[#] Max: {}, Min: {}'.format(ds_train.X.max(),ds_train.X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 20000\n",
    "num_tests = 2000\n",
    "vectorize = lambda x : x.reshape([x.shape[0],-1])\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = [vectorize(ds_train.X[:num_train]), ds_train.y[:num_train], vectorize(ds_val.X[:num_tests]), ds_val.y[:num_tests]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Label : 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19925d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_id = 0\n",
    "Y_plt = Y_test[test_id]\n",
    "X_plt = X_test[test_id]\n",
    "plt.imshow(X_plt.reshape((28,28))*255.0,cmap='gray')\n",
    "print('[*] Label : {}'.format(Y_plt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  5.  9. ...,  9.  2.  3.]\n",
      "[ 0.  5.  9. ...,  9.  2.  3.]\n",
      "0.977\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train,Y_train)\n",
    "y_t = model.predict(vectorize(X_test))\n",
    "accuracy = np.mean(y_t == Y_test)\n",
    "print(Y_test)\n",
    "print(y_t)\n",
    "print(accuracy)\n",
    "#knn_model = prep_bbox(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model_letter = 'B'\n",
    "holdout = 150\n",
    "\n",
    "x_shape, classes = list(X_train.shape[1:]), 10\n",
    "models = {'A': model_a, 'B': model_b, 'C': model_c, 'D': model_d, 'E': model_e, 'F': model_f,\n",
    "              'Z': model_z}\n",
    "\n",
    "x_shape = [28,28,1]\n",
    "x = tf.placeholder(tf.float32, shape=[None] + x_shape)\n",
    "y = tf.placeholder(tf.float32, shape=(None, classes))\n",
    "\n",
    "def to_mnist_shape(XX):\n",
    "    return XX.reshape([XX.shape[0],28,28,1])\n",
    "\n",
    "Y_test_ = convert_to_onehot(Y_test)\n",
    "Y_train_ = convert_to_onehot(Y_train)\n",
    "\n",
    "X_sub = X_test[:holdout]\n",
    "Y_sub = Y_test[:holdout]\n",
    "Y_sub_ = Y_test_[:holdout]\n",
    "X_test = X_test[holdout:]\n",
    "Y_test = Y_test[holdout:]\n",
    "\n",
    "sub_model = models[sub_model_letter](input_shape = [None]+ x_shape,nb_classes = classes)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = lambda x : x.reshape([x.shape[0],-1])\n",
    "def inv_onehot(ys):\n",
    "    assert len(np.shape(ys)) > 1\n",
    "    return np.argmax(ys,axis=1)\n",
    "\n",
    "def convert_to_onehot(ys):\n",
    "    max_y = int(np.max(ys))\n",
    "    y_one_hat = np.zeros([len(ys), max_y + 1], np.float32)\n",
    "    for (i, y) in enumerate(ys):\n",
    "        y_one_hat[i, int(y)] = 1.0\n",
    "    return y_one_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x9e516d0>\n"
     ]
    }
   ],
   "source": [
    "print session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_eval(sess, x, y,x_adv, model, X_test=None, Y_test=None,\n",
    "               feed=None, args=None,debug=False):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of a TF model on some data\n",
    "    :param sess: TF session to use when training the graph\n",
    "    :param x: input placeholder\n",
    "    :param y: output placeholder (for labels)\n",
    "    :param predictions: model output predictions\n",
    "    :param X_test: numpy array with training inputs\n",
    "    :param Y_test: numpy array with training outputs\n",
    "    :param feed: An optional dictionary that is appended to the feeding\n",
    "             dictionary before the session runs. Can be used to feed\n",
    "             the learning phase of a Keras model for instance.\n",
    "    :param args: dict or argparse `Namespace` object.\n",
    "                 Should contain `batch_size`\n",
    "    :param model: (deprecated) if not None, holds model output predictions\n",
    "    :return: a float with the accuracy value\n",
    "    \"\"\"\n",
    "    args = _ArgsWrapper(args or {})\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    \n",
    "    nb_batches = int(math.ceil(float(len(X_test)) / args.batch_size))\n",
    "    assert nb_batches * args.batch_size >= len(X_test)\n",
    "    to_digit = lambda x : np.argmax(x,axis=1)\n",
    "    for batch in range(nb_batches):\n",
    "        start = batch * args.batch_size\n",
    "        end = min(len(X_test), start + args.batch_size)\n",
    "        cur_batch_size = end - start\n",
    "        feed_dict = {x: X_test[start:end], y: Y_test[start:end]}\n",
    "        if feed is not None:\n",
    "            feed_dict.update(feed)\n",
    "        cur_X_test = sess.run(x_adv,feed_dict=feed_dict)\n",
    "        if debug:\n",
    "            debug_dir = 'debug/knn'\n",
    "            ensure_dir(debug_dir)\n",
    "            save_images_files(cur_X_test, output_dir=debug_dir, postfix='adv')\n",
    "            save_images_files(X_test[start:end], output_dir=debug_dir, postfix='orig')\n",
    "            raise ValueException(\"DEBUG\")\n",
    "\n",
    "        cur_preds = model.predict(cur_X_test.reshape([cur_X_test.shape[0],-1]))\n",
    "        cur_acc = np.mean(cur_preds == inv_onehot(Y_test[start:end]))\n",
    "        accuracy += (cur_batch_size * cur_acc)\n",
    "\n",
    "        sys.stdout.write('\\r [-] Eval batch {}/{}: acc: {}'.format(batch,nb_batches,accuracy*1.0/((batch+1)*args.batch_size+1)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "    assert end >= len(X_test)\n",
    "\n",
    "    # Divide by number of examples to get final value\n",
    "    accuracy /= len(X_test)\n",
    "    sys.stdout.write('\\r [*] Done with testing \\n')\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cleverhans/cleverhans/utils_tf.py:112: UserWarning: verbose argument is deprecated and will be removed on 2018-02-11. Instead, use utils.set_log_level(). For backward compatibility, log_level was set to logging.WARNING (30).\n",
      "  warnings.warn(\"verbose argument is deprecated and will be removed\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Done with training 3\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      " [*] Done with training 918\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      " [*] Done with training 7357\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      " [*] Done with training 5844\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      " [*] Done with training 28444\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      " [*] Done with training 83980917\n"
     ]
    }
   ],
   "source": [
    "sess = session\n",
    "knn_model = model\n",
    "nb_classes = classes\n",
    "data_aug = 6\n",
    "rng = np.random.RandomState([2017, 8, 30])\n",
    "model_sub = sub_model\n",
    "preds_sub = model_sub(x)\n",
    "lmbda = 0.1\n",
    "\n",
    "X_sub = X_test[:holdout]\n",
    "Y_sub = Y_test[:holdout]\n",
    "\n",
    "# Define the Jacobian symbolically using TensorFlow\n",
    "grads = jacobian_graph(preds_sub, x, nb_classes)\n",
    "\n",
    "# Train the substitute and augment dataset alternatively\n",
    "for rho in xrange(data_aug):\n",
    "    train_params = {\n",
    "        'nb_epochs': 10,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "    model_train(sess, x, y, preds_sub, to_mnist_shape(X_sub), convert_to_onehot(Y_sub),\n",
    "                init_all=False, verbose=False, args=train_params,\n",
    "                rng=rng, feed={K.learning_phase(): 1})\n",
    "\n",
    "    # If we are not at last substitute training iteration, augment dataset\n",
    "    if rho < data_aug - 1:\n",
    "        print(\"Augmenting substitute training data.\")\n",
    "        # Perform the Jacobian augmentation\n",
    "        X_sub = jacobian_augmentation(sess, x, to_mnist_shape(X_sub), Y_sub.astype(np.int), grads, lmbda, feed={K.learning_phase(): 0})\n",
    "\n",
    "        print(\"Labeling substitute training data.\")\n",
    "        # Label the newly generated synthetic points using the black-box\n",
    "        Y_sub = np.hstack([Y_sub, Y_sub])\n",
    "        X_sub_prev = X_sub[int(len(X_sub) / 2):]\n",
    "        yy = knn_model.predict(vectorize(X_sub_prev))\n",
    "        Y_sub[int(len(X_sub) / 2):] = yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cleverhans/cleverhans/attacks.py:39: UserWarning: CleverHans support for supplying a callable instead of an instance of the cleverhans.model.Model class is deprecated and will be dropped on 2018-01-11.\n",
      "  warnings.warn(\"CleverHans support for supplying a callable\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Done with testing acc: 0.948842218632\n",
      "Test accuracy of oracle on adversarial examples generated using the substitute: 0.952432432432\n"
     ]
    }
   ],
   "source": [
    "eps = 0.3\n",
    "\n",
    "fgsm_par = {'eps': eps, 'ord': np.inf, 'clip_min': 0., 'clip_max': 1.}\n",
    "fgsm = FastGradientMethod(model_sub, sess=sess)\n",
    "\n",
    "# Craft adversarial examples using the substitute\n",
    "eval_params = {'batch_size': 32}\n",
    "x_adv_sub = fgsm.generate(x, **fgsm_par)\n",
    "\n",
    "diff = None\n",
    "\n",
    "x_test = x_adv_sub\n",
    "accuracy = model_eval(sess, x, y,x_adv_sub, model, to_mnist_shape(X_test), convert_to_onehot(Y_test),\n",
    "        args=eval_params, feed={K.learning_phase(): 0},debug=False)\n",
    "print('Test accuracy of oracle on adversarial examples generated '\n",
    "          'using the substitute: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of oracle on adversarial examples generated using the substitute: 0.952432432432\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Test accuracy of oracle on adversarial examples generated '\n",
    "          'using the substitute: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95243243243243247"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
